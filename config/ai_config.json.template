{
  "groq_api_key": "",
  "ai_enabled": false,
  "default_model": "llama-3.3-70b-versatile",
  "temperature": 0.7,
  "max_tokens": 2048
}
